version: '2'
services:

#  lodmilla:
#    image: scambria/lodmilla-frontend
#    ports:
#      - "9999:80"
    
  provesense:
    build: .
    environment:
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql
    volumes:
     - .:/code
     - ./bootstrap:/tmp/bootstrap
    depends_on:
     - blazegraph    
#     - redis
#    restart: always

  provesense-api:
    image: scambria/provesense-api:latest
    ports:
     - "4567:4567"
    environment:
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql

#  redis:
#    image: redis

  blazegraph:
    image: nicholsn/docker-blazegraph
    ports: 
      - "9999:9999"
    volumes:
      - ./ingest:/tmp/ingest
      - .:/tmp/blazegraph
      - ./bootstrap:/tmp/bootstrap

  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    environment:
      - ADVERTISED_HOST=kafka
      - ADVERTISED_PORT=9092    
    restart: always
            
  master:
    build: spark/master
#    command: bin/spark-class org.apache.spark.deploy.master.Master -h master \
#            && bin/spark-submit --jars \
#            | external/kafka-assembly/target/scala-*/spark-streaming-kafka-assembly-*.jar \ 
#            | examples/src/main/python/streaming/direct_kafka_wordcount.py \
#            | kafka:9092 provesense.inbound                  
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master 
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
      LOGGER_NAME: provesense-spark
      LOG_DIR: /var/log/provesense
      LOG_FILE: provesense-spark.log
      LOG_STDOUT: 'False'
      LOG_JSON: 'True'
      LOG_LEVEL: DEBUG      
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data      
      - ./ingest:/tmp/ingest      
      - ./spark:/usr/app
    depends_on:
      - kafka
      - blazegraph
    restart: always

#    entrypoint: |
#      bash -c 'bash -s <<EOF
#      trap "break;exit" SIGHUP SIGINT SIGTERM
#      while /bin/true; do
#        su -s "/bin/bash" -c "bin/spark-submit --jars " \
#         "external/kafka-assembly/target/scala-*/spark-streaming-kafka-assembly-*.jar " \ 
#         "examples/src/main/python/streaming/direct_kafka_wordcount.py " \
#         "kafka:9092 provesense.inbound"
#        sleep 3600
#      done
#      EOF'
  worker:
#    image: gettyimages/spark
    build: spark/worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
      LOGGER_NAME: provesense-spark
      LOG_DIR: /var/log/provesense
      LOG_FILE: provesense-spark.log
      LOG_STDOUT: 'False'
      LOG_JSON: 'True'
      LOG_LEVEL: DEBUG            
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8081:8081
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data 
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always
    
  worker2:
#    image: gettyimages/spark
    build: spark/worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker2
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
      LOGGER_NAME: provesense-spark
      LOG_DIR: /var/log/provesense
      LOG_FILE: provesense-spark.log
      LOG_STDOUT: 'False'
      LOG_JSON: 'True'
      LOG_LEVEL: DEBUG            
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8082:8081
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always    
    
  worker3:
#    image: gettyimages/spark
    build: spark/worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker3
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
      LOGGER_NAME: provesense-spark
      LOG_DIR: /var/log/provesense
      LOG_FILE: provesense-spark.log
      LOG_STDOUT: 'False'
      LOG_JSON: 'True'
      LOG_LEVEL: DEBUG            
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8083:8081
    volumes:
      - ./conf/worker:/conf
      - ./data:/tmp/data
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always 
    
  elasticsearch:
#    image: elasticsearch:5.0.0-rc1
    image: elasticsearch:latest 
    command: elasticsearch -Des.network.host=0.0.0.0
    ports:
      - "9200:9200"
      - "9300:9300"
  
  logstash:
    image: logstash:latest
    command: logstash -f /etc/logstash/conf.d/logstash.conf
    volumes:
      - ./logs:/var/log/
      - ./elk/spark-logstash.conf:/etc/logstash/conf.d/logstash.conf
      - ./elk/logs-template.json:/etc/logstash/templates/logs-template.json      
    ports:
      - "5000:5000"
    depends_on:
      - elasticsearch
      
  kibana:
#    image: kibana:5.0.0-rc1
    image: kibana:latest
#    volumes:
#      - ./elk:/opt/kibana/config/
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
