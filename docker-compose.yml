version: '2'
services:

  #For bootstrapping the graph database    
  provesense:
    build: .
    environment:
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql
    volumes:
#     - .:/code
     - ./bootstrap:/tmp/bootstrap
    depends_on:
     - blazegraph    
#     - redis
#    restart: always

  #viz
  lodmilla:
    image: scambria/lodmilla-frontend:provesense
    ports:
      - "9998:80"

  ld-r:
    image: scambria/ld-r
    ports: 
      - "4000:4000"
    volumes:
      - ./ld-r-configs:/ld-r/configs
      - ./ld-r-services:/ld-r/services
    restart: always
      
  #API
  provesense-api:
    image: scambria/provesense-api:latest
    ports:
     - "4567:4567"
    environment:
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql

  #graph database
  blazegraph:
    image: nicholsn/docker-blazegraph
    ports: 
      - "9999:9999"
    volumes:
      - .:/tmp/blazegraph
      - ./bootstrap:/tmp/bootstrap

  #kafka + zookeeper
  kafka:
    image: spotify/kafka
    ports:
      - "9092:9092"
      - "2181:2181"
    environment:
      - ADVERTISED_HOST=kafka
      - ADVERTISED_PORT=9092    
    restart: always

  #Spark streaming master + 3 workers for ingestion            
  master:
    image: scambria/provesense-ingest
#TODO: submit job when container starts; this approach fails
#    command: bin/spark-class org.apache.spark.deploy.master.Master -h master \
#            && bin/spark-submit --jars \
#            | ./jars/spark-streaming-kafka-0-8-assembly_2.11-2.1.0-SNAPSHOT.jar \ 
#            | python/direct_stream.py kafka:9092 provesense.inbound
    command: bin/spark-class org.apache.spark.deploy.master.Master -h master 
    hostname: master
    environment:
      MASTER: spark://master:7077
      SPARK_CONF_DIR: /conf
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
      LOGGER_NAME: provesense-spark
      LOG_DIR: /var/log/provesense
      LOG_FILE: provesense-spark.log
      LOG_STDOUT: 'False'
      LOG_JSON: 'True'
      LOG_LEVEL: DEBUG      
    expose:
      - 7001
      - 7002
      - 7003
      - 7004
      - 7005
      - 7006
      - 7077
      - 6066
    ports:
      - 4040:4040
      - 6066:6066
      - 7077:7077
      - 8080:8080
    volumes:
      - ./data:/tmp/data      
      - ./ingest:/tmp/ingest      
      - ./spark:/usr/app
    depends_on:
      - kafka
      - blazegraph
    restart: always

  worker1:
    image: scambria/provesense-ingest
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker1
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8081:8081
    volumes:
      - ./data:/tmp/data
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always 
    
  worker2:
    image: scambria/provesense-ingest
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker2
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8082:8081
    volumes:
      - ./data:/tmp/data
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always 
    
  worker3:
    image: scambria/provesense-ingest
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077 
    hostname: worker3
    environment:
      SPARK_CONF_DIR: /conf
      SPARK_WORKER_CORES: 2
      SPARK_WORKER_MEMORY: 1g
      SPARK_WORKER_PORT: 8881
      SPARK_WORKER_WEBUI_PORT: 8081
      SPARK_PUBLIC_DNS: localhost
      SPARQL_ENDPOINT: http://blazegraph:9999/blazegraph/sparql      
    links:
      - master
    expose:
      - 7012
      - 7013
      - 7014
      - 7015
      - 7016
      - 8881
    ports:
      - 8083:8081
    volumes:
      - ./data:/tmp/data
      - ./logs:/usr/spark-2.0.1/work
    depends_on:
      - master
    restart: always

#  redis:
#    image: redis

#ELK for logging    
#may need to run `sudo sysctl -w vm.max_map_count=262144` on the host prior to booting
#  elasticsearch:
#    image: elasticsearch:latest 
#    command: elasticsearch 
#    ports:
#      - "9200:9200"
#      - "9300:9300"
#    restart: always 
      
#  logstash:
#    image: logstash:latest
#    command: logstash -f /etc/logstash/conf.d/logstash.conf
#    volumes:
#      - ./logs:/tmp/logs
#      - ./elk/spark-logstash.conf:/etc/logstash/conf.d/logstash.conf
#      - ./elk/logs-template.json:/etc/logstash/templates/logs-template.json      
#    ports:
#      - "5000:5000"
#    depends_on:
#      - elasticsearch
#    restart: always       
      
#  kibana:
#    image: kibana:latest 
#    volumes:
#      - ./elk:/opt/kibana/config/
#    ports:
#      - "5601:5601"
#    depends_on:
#      - elasticsearch
#    restart: always 
      
      
